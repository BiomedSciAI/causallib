{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Probability Weighting Model (scikit-learn score adapted)\n",
    "Inverse probability weighting is a basic model to obtain average effect estimation.\n",
    "\n",
    "It calculates the probability of each sample to belong to its group,   \n",
    "and use its inverse as the weight of that sample:\n",
    "$$\n",
    "w_i = \\frac{1}{\\Pr[A=a_i | X_i]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from causallib.datasets import load_nhefs\n",
    "from causallib.estimation import IPW\n",
    "from causallib.evaluation import PropensityEvaluator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use built-in scoring from scikit-learn, we need to either supply a \"scoring\" function or implement a \"score\" method. For now, we are doing it with a score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoredIPW(IPW):\n",
    "    def fit(self, dataX,Y):\n",
    "        X = dataX.copy()\n",
    "        a = X.pop(\"a\")\n",
    "        return super().fit(X,a)\n",
    "        \n",
    "    def score(self,dataX,Y,metrics=None):\n",
    "        from sklearn import metrics\n",
    "        if metrics is None:\n",
    "            metrics = {\"roc_auc\": metrics.roc_auc_score,\n",
    "           \"avg_precision\": metrics.average_precision_score,}\n",
    "        \n",
    "        X = dataX.copy()\n",
    "        a = X.pop(\"a\")\n",
    "        w = self.compute_weights(X,a)\n",
    "        yhat,oneminusyhat = self.learner.predict_proba(X).T\n",
    "        #we'll use negative roc_auc because lower is better\n",
    "        score = -metrics.roc_auc_score(a,yhat,sample_weight=w)    \n",
    "        return score\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"use_stabilized\": self.use_stabilized, \"truncate_eps\": self.truncate_eps, \"learner\":self.learner}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data:\n",
    "The effect of quitting to smoke on weight loss.  \n",
    "Data example is taken from [Hernan and Robins Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokeintensity</th>\n",
       "      <th>smokeyrs</th>\n",
       "      <th>wt71</th>\n",
       "      <th>active_1</th>\n",
       "      <th>active_2</th>\n",
       "      <th>education_2</th>\n",
       "      <th>education_3</th>\n",
       "      <th>education_4</th>\n",
       "      <th>education_5</th>\n",
       "      <th>exercise_1</th>\n",
       "      <th>exercise_2</th>\n",
       "      <th>age^2</th>\n",
       "      <th>wt71^2</th>\n",
       "      <th>smokeintensity^2</th>\n",
       "      <th>smokeyrs^2</th>\n",
       "      <th>qsmk</th>\n",
       "      <th>wt82_71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>79.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1764</td>\n",
       "      <td>6247.3216</td>\n",
       "      <td>900</td>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.093960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>58.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>3437.4769</td>\n",
       "      <td>400</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>2.604970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>56.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3136</td>\n",
       "      <td>3227.3761</td>\n",
       "      <td>400</td>\n",
       "      <td>676</td>\n",
       "      <td>0</td>\n",
       "      <td>9.414486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>59.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4624</td>\n",
       "      <td>3530.7364</td>\n",
       "      <td>9</td>\n",
       "      <td>2809</td>\n",
       "      <td>0</td>\n",
       "      <td>4.990117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>87.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>7584.6681</td>\n",
       "      <td>400</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>4.989251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  race  sex  smokeintensity  smokeyrs   wt71  active_1  active_2  \\\n",
       "0   42     1    0              30        29  79.04         0         0   \n",
       "1   36     0    0              20        24  58.63         0         0   \n",
       "2   56     1    1              20        26  56.81         0         0   \n",
       "3   68     1    0               3        53  59.42         1         0   \n",
       "4   40     0    0              20        19  87.09         1         0   \n",
       "\n",
       "   education_2  education_3  education_4  education_5  exercise_1  exercise_2  \\\n",
       "0            0            0            0            0           0           1   \n",
       "1            1            0            0            0           0           0   \n",
       "2            1            0            0            0           0           1   \n",
       "3            0            0            0            0           0           1   \n",
       "4            1            0            0            0           1           0   \n",
       "\n",
       "   age^2     wt71^2  smokeintensity^2  smokeyrs^2  qsmk    wt82_71  \n",
       "0   1764  6247.3216               900         841     0 -10.093960  \n",
       "1   1296  3437.4769               400         576     0   2.604970  \n",
       "2   3136  3227.3761               400         676     0   9.414486  \n",
       "3   4624  3530.7364                 9        2809     0   4.990117  \n",
       "4   1600  7584.6681               400         361     0   4.989251  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_nhefs()\n",
    "data.X.join(data.a).join(data.y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the sklearn api we need X and Y for fit. Our model uses X, Y and a. For this version we put a inside X. Now `cross_val_score` works out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48442185, -0.48038368, -0.50390762, -0.5555427 , -0.5734839 ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ipw = ScoredIPW(LogisticRegression(solver=\"liblinear\"))\n",
    "\n",
    "dataX = data.X.copy()\n",
    "dataX[\"a\"] = data.a\n",
    "\n",
    "ipw.fit(dataX,data.y)\n",
    "\n",
    "cross_val_score(ipw,dataX,data.y,cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can go for a long walk in the world of sklearn classifiers with `GridSearchCV`. Only those with a `predict_proba` method are usable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    #KNeighborsClassifier(3),\n",
    "    #SVC(kernel=\"linear\", C=0.025,probability=True),\n",
    "    #SVC(gamma=2, C=1,probability=True),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver=\"liblinear\"),\n",
    "    LogisticRegression()\n",
    "]\n",
    "classifiers = [\n",
    "    LogisticRegression(solver=\"liblinear\"),\n",
    "    LogisticRegression(),\n",
    "    LogisticRegression(penalty=\"l1\", C=0.01, max_iter=500, solver='liblinear'),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    #SVC(kernel=\"linear\", C=0.025,probability=True),\n",
    "    \n",
    "]\n",
    "gscv = GridSearchCV(ScoredIPW(learner=LogisticRegression(solver=\"liblinear\")),param_grid={\"learner\":classifiers[:4],\"use_stabilized\":[True,False]})\n",
    "search = gscv.fit(dataX,data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_learner</th>\n",
       "      <th>param_use_stabilized</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression(C=0.01, max_iter=500, penalty='l1', solver='liblinear')</th>\n",
       "      <th>True</th>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>{'learner': LogisticRegression(C=0.01, max_ite...</td>\n",
       "      <td>-0.471578</td>\n",
       "      <td>-0.506176</td>\n",
       "      <td>-0.503257</td>\n",
       "      <td>-0.528899</td>\n",
       "      <td>-0.522056</td>\n",
       "      <td>-0.506393</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.019660</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>{'learner': LogisticRegression(C=0.01, max_ite...</td>\n",
       "      <td>-0.471620</td>\n",
       "      <td>-0.506170</td>\n",
       "      <td>-0.503590</td>\n",
       "      <td>-0.528619</td>\n",
       "      <td>-0.522088</td>\n",
       "      <td>-0.506418</td>\n",
       "      <td>0.019786</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression()</th>\n",
       "      <th>True</th>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>{'learner': LogisticRegression(), 'use_stabili...</td>\n",
       "      <td>-0.466436</td>\n",
       "      <td>-0.495251</td>\n",
       "      <td>-0.532969</td>\n",
       "      <td>-0.529717</td>\n",
       "      <td>-0.539680</td>\n",
       "      <td>-0.512811</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.298289</td>\n",
       "      <td>0.088396</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>{'learner': LogisticRegression(), 'use_stabili...</td>\n",
       "      <td>-0.466436</td>\n",
       "      <td>-0.495251</td>\n",
       "      <td>-0.532969</td>\n",
       "      <td>-0.529717</td>\n",
       "      <td>-0.539680</td>\n",
       "      <td>-0.512811</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression(solver='liblinear')</th>\n",
       "      <th>False</th>\n",
       "      <td>0.010276</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>{'learner': LogisticRegression(solver='libline...</td>\n",
       "      <td>-0.484422</td>\n",
       "      <td>-0.480384</td>\n",
       "      <td>-0.503908</td>\n",
       "      <td>-0.555543</td>\n",
       "      <td>-0.573484</td>\n",
       "      <td>-0.519548</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>{'learner': LogisticRegression(solver='libline...</td>\n",
       "      <td>-0.484422</td>\n",
       "      <td>-0.480384</td>\n",
       "      <td>-0.503908</td>\n",
       "      <td>-0.555543</td>\n",
       "      <td>-0.573484</td>\n",
       "      <td>-0.519548</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLPClassifier(alpha=1, max_iter=1000)</th>\n",
       "      <th>True</th>\n",
       "      <td>1.398105</td>\n",
       "      <td>0.381477</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>{'learner': MLPClassifier(alpha=1, max_iter=10...</td>\n",
       "      <td>-0.989326</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.997861</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1.635659</td>\n",
       "      <td>0.117899</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>{'learner': MLPClassifier(alpha=1, max_iter=10...</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         mean_fit_time  \\\n",
       "param_learner                                      param_use_stabilized                  \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                       0.027884   \n",
       "                                                   False                      0.019660   \n",
       "LogisticRegression()                               True                       0.206400   \n",
       "                                                   False                      0.298289   \n",
       "LogisticRegression(solver='liblinear')             False                      0.010276   \n",
       "                                                   True                       0.011518   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                       1.398105   \n",
       "                                                   False                      1.635659   \n",
       "\n",
       "                                                                         std_fit_time  \\\n",
       "param_learner                                      param_use_stabilized                 \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                      0.012213   \n",
       "                                                   False                     0.000908   \n",
       "LogisticRegression()                               True                      0.052080   \n",
       "                                                   False                     0.088396   \n",
       "LogisticRegression(solver='liblinear')             False                     0.000779   \n",
       "                                                   True                      0.000995   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                      0.381477   \n",
       "                                                   False                     0.117899   \n",
       "\n",
       "                                                                         mean_score_time  \\\n",
       "param_learner                                      param_use_stabilized                    \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                         0.006433   \n",
       "                                                   False                        0.004275   \n",
       "LogisticRegression()                               True                         0.012949   \n",
       "                                                   False                        0.011026   \n",
       "LogisticRegression(solver='liblinear')             False                        0.003908   \n",
       "                                                   True                         0.004789   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                         0.017522   \n",
       "                                                   False                        0.020842   \n",
       "\n",
       "                                                                         std_score_time  \\\n",
       "param_learner                                      param_use_stabilized                   \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                        0.002875   \n",
       "                                                   False                       0.000520   \n",
       "LogisticRegression()                               True                        0.000552   \n",
       "                                                   False                       0.000842   \n",
       "LogisticRegression(solver='liblinear')             False                       0.000209   \n",
       "                                                   True                        0.000264   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                        0.004077   \n",
       "                                                   False                       0.005405   \n",
       "\n",
       "                                                                                                                    params  \\\n",
       "param_learner                                      param_use_stabilized                                                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                  {'learner': LogisticRegression(C=0.01, max_ite...   \n",
       "                                                   False                 {'learner': LogisticRegression(C=0.01, max_ite...   \n",
       "LogisticRegression()                               True                  {'learner': LogisticRegression(), 'use_stabili...   \n",
       "                                                   False                 {'learner': LogisticRegression(), 'use_stabili...   \n",
       "LogisticRegression(solver='liblinear')             False                 {'learner': LogisticRegression(solver='libline...   \n",
       "                                                   True                  {'learner': LogisticRegression(solver='libline...   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                  {'learner': MLPClassifier(alpha=1, max_iter=10...   \n",
       "                                                   False                 {'learner': MLPClassifier(alpha=1, max_iter=10...   \n",
       "\n",
       "                                                                         split0_test_score  \\\n",
       "param_learner                                      param_use_stabilized                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                          -0.471578   \n",
       "                                                   False                         -0.471620   \n",
       "LogisticRegression()                               True                          -0.466436   \n",
       "                                                   False                         -0.466436   \n",
       "LogisticRegression(solver='liblinear')             False                         -0.484422   \n",
       "                                                   True                          -0.484422   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                          -0.989326   \n",
       "                                                   False                         -0.999998   \n",
       "\n",
       "                                                                         split1_test_score  \\\n",
       "param_learner                                      param_use_stabilized                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                          -0.506176   \n",
       "                                                   False                         -0.506170   \n",
       "LogisticRegression()                               True                          -0.495251   \n",
       "                                                   False                         -0.495251   \n",
       "LogisticRegression(solver='liblinear')             False                         -0.480384   \n",
       "                                                   True                          -0.480384   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                          -1.000000   \n",
       "                                                   False                         -1.000000   \n",
       "\n",
       "                                                                         split2_test_score  \\\n",
       "param_learner                                      param_use_stabilized                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                          -0.503257   \n",
       "                                                   False                         -0.503590   \n",
       "LogisticRegression()                               True                          -0.532969   \n",
       "                                                   False                         -0.532969   \n",
       "LogisticRegression(solver='liblinear')             False                         -0.503908   \n",
       "                                                   True                          -0.503908   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                          -1.000000   \n",
       "                                                   False                         -1.000000   \n",
       "\n",
       "                                                                         split3_test_score  \\\n",
       "param_learner                                      param_use_stabilized                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                          -0.528899   \n",
       "                                                   False                         -0.528619   \n",
       "LogisticRegression()                               True                          -0.529717   \n",
       "                                                   False                         -0.529717   \n",
       "LogisticRegression(solver='liblinear')             False                         -0.555543   \n",
       "                                                   True                          -0.555543   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                          -0.999977   \n",
       "                                                   False                               NaN   \n",
       "\n",
       "                                                                         split4_test_score  \\\n",
       "param_learner                                      param_use_stabilized                      \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                          -0.522056   \n",
       "                                                   False                         -0.522088   \n",
       "LogisticRegression()                               True                          -0.539680   \n",
       "                                                   False                         -0.539680   \n",
       "LogisticRegression(solver='liblinear')             False                         -0.573484   \n",
       "                                                   True                          -0.573484   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                          -1.000000   \n",
       "                                                   False                         -0.999990   \n",
       "\n",
       "                                                                         mean_test_score  \\\n",
       "param_learner                                      param_use_stabilized                    \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                        -0.506393   \n",
       "                                                   False                       -0.506418   \n",
       "LogisticRegression()                               True                        -0.512811   \n",
       "                                                   False                       -0.512811   \n",
       "LogisticRegression(solver='liblinear')             False                       -0.519548   \n",
       "                                                   True                        -0.519548   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                        -0.997861   \n",
       "                                                   False                             NaN   \n",
       "\n",
       "                                                                         std_test_score  \\\n",
       "param_learner                                      param_use_stabilized                   \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                        0.019869   \n",
       "                                                   False                       0.019786   \n",
       "LogisticRegression()                               True                        0.027832   \n",
       "                                                   False                       0.027832   \n",
       "LogisticRegression(solver='liblinear')             False                       0.037992   \n",
       "                                                   True                        0.037992   \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                        0.004267   \n",
       "                                                   False                            NaN   \n",
       "\n",
       "                                                                         rank_test_score  \n",
       "param_learner                                      param_use_stabilized                   \n",
       "LogisticRegression(C=0.01, max_iter=500, penalt... True                                1  \n",
       "                                                   False                               2  \n",
       "LogisticRegression()                               True                                3  \n",
       "                                                   False                               3  \n",
       "LogisticRegression(solver='liblinear')             False                               5  \n",
       "                                                   True                                6  \n",
       "MLPClassifier(alpha=1, max_iter=1000)              True                                7  \n",
       "                                                   False                               8  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_,).set_index([\"param_learner\",\"param_use_stabilized\"]).sort_values(\"rank_test_score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
